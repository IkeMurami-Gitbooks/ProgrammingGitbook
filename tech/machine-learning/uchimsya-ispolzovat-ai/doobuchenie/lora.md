# LoRA

LoRA (Low-Rank Adaptation) — это способ эффективно дообучить большую генеративную модель (LLM или диффузионную) под ваш стиль, объект или задачу без полного переобучения всей модели.

Как это работает (вкратце):

* Базовые веса модели замораживаются.
* В некоторые слои (обычно линейные/внимание) добавляются маленькие «адаптеры» — две низкоранговые матрицы.
* Обучаются только эти адаптеры, а на инференсе они добавляются к базовым весам с коэффициентом силы (scale).
* Результат — маленький файл (часто несколько–десятки мегабайт), который можно подключать/отключать и комбинировать.

Зачем это нужно:

* Мало данных и ресурсов: обучается на 20–200 изображениях (для имидж-моделей) за часы на 1 GPU.
* Маленький размер и быстрый инференс.
* Комбинируемость: можно смешивать несколько LoRA (например, стиль + конкретный персонаж).
* Базовая модель не «ломается» — её поведение сохраняется, а LoRA можно масштабировать по силе.

В генерации изображений (SD/SDXL/FLUX и др.) LoRA используют для:

* Стиля (художественная манера, рендер-стиль, брендинг).
* Конкретных персонажей, лиц, предметов, продуктов.
* Доменных визуальных задач (технические иллюстрации, медицинские типы снимков и т. п.).
